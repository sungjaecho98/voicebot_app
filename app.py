import streamlit as st
from audiorecorder import audiorecorder
from openai_service import stt, ask_gpt, tts

# Streamlit ë©”ì¸ í˜ì´ì§€ êµ¬ì„±
def main():
    st.set_page_config(
        page_title='ğŸ˜Voice ChatbotğŸ˜',
        page_icon="ğŸ¤",
        layout='wide'
    )
    st.header('ğŸ¤Voice ChatbotğŸ¤')
    st.markdown('---')

    #ì²˜ë¦¬ ìˆœì„œ ì•ˆë‚´ (Expander)
    with st.expander('Voice Chatbot í”„ë¡œê·¸ë¨ ì²˜ë¦¬ì ˆì°¨', expanded=False):
        st.write(
            """
            1. ë…¹ìŒí•˜ê¸° ë²„íŠ¼ì„ ëˆŒëŸ¬ ì§ˆë¬¸ì„ ë…¹ìŒí•©ë‹ˆë‹¤.
            2. ë…¹ìŒì´ ì™„ë£Œë˜ë©´ ìë™ìœ¼ë¡œ Whisperëª¨ë¸ì„ ì´ìš©í•´ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. 
            3. ë³€í™˜ëœ í…ìŠ¤íŠ¸ë¡œ LLMì— ì§ˆì˜í›„ ì‘ë‹µì„ ë°›ìŠµë‹ˆë‹¤.
            4. LLMì˜ ì‘ë‹µì„ ë‹¤ì‹œ TTSëª¨ë¸ì„ ì‚¬ìš©í•´ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì´ë¥¼ ì‚¬ìš©ìì—ê²Œ ë“¤ë ¤ì¤ë‹ˆë‹¤.
            5. ëª¨ë“  ì§ˆë¬¸/ë‹µë³€ì€ ì±„íŒ…í˜•ì‹ì˜ í…ìŠ¤íŠ¸ë¡œ ì œê³µí•©ë‹ˆë‹¤.
            """
        )

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'messages' not in st.session_state:
        st.session_state['messages'] = [
            {'role': 'system', 'content': 'ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì±—ë´‡ì…ë‹ˆë‹¤.'}
        ]
    if 'check_reset' not in st.session_state:
        st.session_state['check_reset'] = False

    #ì‚¬ì´ë“œë°”: ëª¨ë¸ ì„ íƒ, ì´ˆê¸°í™” ë²„íŠ¼
    with st.sidebar:
        model = st.radio(label='GPT ëª¨ë¸', options=['gpt-4.1', 'gpt-4o', 'gpt-4o-mini'], index=2)
        print(f'model={model}')

        if st.button(label='ì´ˆê¸°í™”'):
            st.session_state['check_reset'] = True
            st.session_state['messages'] = [
                {'role': 'system', 'content': 'ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì±—ë´‡ì…ë‹ˆë‹¤.'}
            ]

    # ë©”ì¸ ì¸í„°í˜ì´ìŠ¤ - ì¢Œìš° ì—´ êµ¬ì„±
    col1, col2 = st.columns(2)
    #ì™¼ìª½: ğŸ™ï¸ ìŒì„± ì…ë ¥ ë° ì²˜ë¦¬
    with col1:
        st.subheader('ë…¹ìŒí•˜ê¸°')

        audio = audiorecorder()

        if (audio.duration_seconds > 0) and (not st.session_state['check_reset']):
            # ìŒì› ì¬ìƒ
            st.audio(audio.export().read())

            # stt ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ì¶”ì¶œ
            prompt = stt(audio)
            print(f'prompt={prompt}')

            # chat completion í˜¸ì¶œ
            # - messagesì— ì¶”ê°€
            st.session_state['messages'].append({'role': 'user', 'content': prompt})
            # - llm ìš”ì²­
            response = ask_gpt(st.session_state['messages'], model)
            st.session_state['messages'].append({'role': 'assistant', 'content': response})
            print(f'response={response}')

            # llm ì‘ë‹µì„ ttsëª¨ë¸ì„ í†µí•´ ìŒì›íŒŒì¼ë¡œ ë³€í™˜/ì¬ìƒ
            base64_encoded = tts(response)
            # print(base64_encoded)
            st.html(f'''
            <audio autoplay='true'>
                <source src='data:audio/mp3;base64,{base64_encoded}' type='audio/mp3'/>
            </audio>
            ''')

    #ì˜¤ë¥¸ìª½: ğŸ’¬ ì§ˆë¬¸/ë‹µë³€ ì±„íŒ… ê¸°ë¡
    with col2:
        st.subheader('ì§ˆë¬¸/ë‹µë³€')

        if (audio.duration_seconds > 0) and (not st.session_state['check_reset']):
            for message in st.session_state['messages']:
                role = message['role']  # system/user/assistant
                content = message['content']

                if role == 'system':
                    continue

                with st.chat_message(role):
                    st.markdown(content)
        else:
            st.session_state['check_reset'] = False  # ì´ˆê¸°í™”ìƒíƒœ ê°’ì€ ì›ë³µ

#  ì•± ì‹¤í–‰
if __name__ == '__main__':
    main()